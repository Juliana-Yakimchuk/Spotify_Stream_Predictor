{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31230c00-621e-447b-931e-7630d66f2313",
   "metadata": {},
   "source": [
    "### This notebook contains early-stage experimentation, exploratory analysis, and feature prototyping.The final, cleaned analysis and modeling pipeline is available on the `main` branch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f907e",
   "metadata": {},
   "source": [
    "## The Data Collection/Extraction Stages.\n",
    "### The goal is to have audio features for each track as well as # of streams across all platforms. We will attempt to predict the # of streams based on the track's audio features.\n",
    "1. Pull a sample of metal tracks released starting 2005 from Chartmetric. The data includes Spotify and other platforms' # of streams, as well as ISRC (International Standard Recording Code). This number is shared between multiple versions of the same song (e.g. album vs. single, remastered versions etc.), but belongs to essential the same track.\n",
    "2. Spotify no longer allows to use its data for AI training and deprecated the API for pulling tracks' audio features, so we will use a third party API - Reccobeats to calculate audio features for each track.\n",
    "3. Need to create a script to pull audio features from Reccobeats based on ISCRC for each song on the Chartmetric dataset.\n",
    "4. Since ISRC can pull multiple versions of the same song, need to calculate the mean for each audio feature to closely approximate the most popular version's features. Reccobeats API currently does not provide the song's stream data, so it is not possible to pull only the audio features of the main version. Averaging out accross multiple versions of the song would be a solid option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc818537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "#data analysis\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad8904",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "299558f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artists</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>ISRC</th>\n",
       "      <th>All Time Rank</th>\n",
       "      <th>Track Score</th>\n",
       "      <th>Spotify Streams</th>\n",
       "      <th>Spotify Playlist Count</th>\n",
       "      <th>Spotify Playlist Reach</th>\n",
       "      <th>...</th>\n",
       "      <th>Deezer Playlist Count</th>\n",
       "      <th>Deezer Playlist Reach</th>\n",
       "      <th>Amazon Music Playlist Count</th>\n",
       "      <th>Pandora Streams</th>\n",
       "      <th>Pandora Track Stations</th>\n",
       "      <th>Soundcloud Streams</th>\n",
       "      <th>Shazams</th>\n",
       "      <th>TIDAL Popularity</th>\n",
       "      <th>Explicit Track</th>\n",
       "      <th>Shortlists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Psychosocial</td>\n",
       "      <td>Psychosocial</td>\n",
       "      <td>Slipknot</td>\n",
       "      <td>2008-07-08</td>\n",
       "      <td>NLA320886993</td>\n",
       "      <td>1,912</td>\n",
       "      <td>97.14</td>\n",
       "      <td>808,166,393</td>\n",
       "      <td>172,861</td>\n",
       "      <td>23,649,176</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>277,509</td>\n",
       "      <td>34.0</td>\n",
       "      <td>128,354,144</td>\n",
       "      <td>82,682</td>\n",
       "      <td>14,547,258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stricken</td>\n",
       "      <td>Stricken</td>\n",
       "      <td>Disturbed</td>\n",
       "      <td>2005-07-20</td>\n",
       "      <td>USRE10500766</td>\n",
       "      <td>6,688</td>\n",
       "      <td>95.45</td>\n",
       "      <td>466,331,168</td>\n",
       "      <td>92,604</td>\n",
       "      <td>17,799,301</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>201,307</td>\n",
       "      <td>24.0</td>\n",
       "      <td>316,520,872</td>\n",
       "      <td>63,786</td>\n",
       "      <td>6,196,954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unsainted</td>\n",
       "      <td>Unsainted</td>\n",
       "      <td>Slipknot</td>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>NLA321900089</td>\n",
       "      <td>8,169</td>\n",
       "      <td>95.10</td>\n",
       "      <td>379,175,553</td>\n",
       "      <td>85,612</td>\n",
       "      <td>9,081,286</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>109,511</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37,473,127</td>\n",
       "      <td>13,403</td>\n",
       "      <td>633,800</td>\n",
       "      <td>524,502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sanctified with Dynamite</td>\n",
       "      <td>Blood of the Saints</td>\n",
       "      <td>Powerwolf</td>\n",
       "      <td>2011-07-29</td>\n",
       "      <td>USMBR1108247</td>\n",
       "      <td>9,865</td>\n",
       "      <td>94.75</td>\n",
       "      <td>62,337,875</td>\n",
       "      <td>19,076</td>\n",
       "      <td>1,982,796</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4,037</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154,715</td>\n",
       "      <td>62,296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nero Forte</td>\n",
       "      <td>We Are Not Your Kind</td>\n",
       "      <td>Slipknot</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>NLA321900097</td>\n",
       "      <td>12,992</td>\n",
       "      <td>94.19</td>\n",
       "      <td>205,529,233</td>\n",
       "      <td>52,321</td>\n",
       "      <td>6,025,170</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>67,513</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20,807,156</td>\n",
       "      <td>5,627</td>\n",
       "      <td>398,199</td>\n",
       "      <td>304,875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Track            Album Name    Artists Release Date  \\\n",
       "0              Psychosocial          Psychosocial   Slipknot   2008-07-08   \n",
       "1                  Stricken              Stricken  Disturbed   2005-07-20   \n",
       "2                 Unsainted             Unsainted   Slipknot   2019-05-16   \n",
       "3  Sanctified with Dynamite   Blood of the Saints  Powerwolf   2011-07-29   \n",
       "4                Nero Forte  We Are Not Your Kind   Slipknot   2019-08-09   \n",
       "\n",
       "           ISRC All Time Rank  Track Score Spotify Streams  \\\n",
       "0  NLA320886993         1,912        97.14     808,166,393   \n",
       "1  USRE10500766         6,688        95.45     466,331,168   \n",
       "2  NLA321900089         8,169        95.10     379,175,553   \n",
       "3  USMBR1108247         9,865        94.75      62,337,875   \n",
       "4  NLA321900097        12,992        94.19     205,529,233   \n",
       "\n",
       "  Spotify Playlist Count Spotify Playlist Reach  ... Deezer Playlist Count  \\\n",
       "0                172,861             23,649,176  ...                  20.0   \n",
       "1                 92,604             17,799,301  ...                   7.0   \n",
       "2                 85,612              9,081,286  ...                  13.0   \n",
       "3                 19,076              1,982,796  ...                   2.0   \n",
       "4                 52,321              6,025,170  ...                   7.0   \n",
       "\n",
       "  Deezer Playlist Reach Amazon Music Playlist Count Pandora Streams  \\\n",
       "0               277,509                        34.0     128,354,144   \n",
       "1               201,307                        24.0     316,520,872   \n",
       "2               109,511                        24.0      37,473,127   \n",
       "3                 4,037                        11.0             NaN   \n",
       "4                67,513                         4.0      20,807,156   \n",
       "\n",
       "  Pandora Track Stations Soundcloud Streams  Shazams  TIDAL Popularity  \\\n",
       "0                 82,682         14,547,258      NaN               NaN   \n",
       "1                 63,786          6,196,954      NaN               NaN   \n",
       "2                 13,403            633,800  524,502               NaN   \n",
       "3                    NaN            154,715   62,296               NaN   \n",
       "4                  5,627            398,199  304,875               NaN   \n",
       "\n",
       "  Explicit Track  Shortlists  \n",
       "0              0         NaN  \n",
       "1              0         NaN  \n",
       "2              1         NaN  \n",
       "3              0         NaN  \n",
       "4              1         NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load chartmetrics data\n",
    "raw_data_path =  project_root/\"data\"/\"raw\"\n",
    "chart_ds = pd.read_csv(raw_data_path/ \"chartmetric_raw.csv\")\n",
    "print(chart_ds.shape)\n",
    "#/Users/test/Desktop/Data_Science/GIT/\n",
    "chart_ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1e65f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6800 entries, 0 to 6799\n",
      "Data columns (total 30 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Track                        6800 non-null   object \n",
      " 1   Album Name                   6800 non-null   object \n",
      " 2   Artists                      6800 non-null   object \n",
      " 3   Release Date                 6800 non-null   object \n",
      " 4   ISRC                         6800 non-null   object \n",
      " 5   All Time Rank                6800 non-null   object \n",
      " 6   Track Score                  6800 non-null   float64\n",
      " 7   Spotify Streams              6762 non-null   object \n",
      " 8   Spotify Playlist Count       6800 non-null   object \n",
      " 9   Spotify Playlist Reach       6800 non-null   object \n",
      " 10  Spotify Popularity           6749 non-null   object \n",
      " 11  YouTube Views                3642 non-null   object \n",
      " 12  YouTube Likes                3640 non-null   object \n",
      " 13  TikTok Videos                1199 non-null   object \n",
      " 14  TikTok Likes                 1285 non-null   object \n",
      " 15  TikTok Views                 1285 non-null   object \n",
      " 16  YouTube Playlist Reach       309 non-null    object \n",
      " 17  Apple Music Playlist Count   1289 non-null   float64\n",
      " 18  AirPlay Spins                2883 non-null   object \n",
      " 19  SiriusXM Spins               457 non-null    float64\n",
      " 20  Deezer Playlist Count        664 non-null    float64\n",
      " 21  Deezer Playlist Reach        659 non-null    object \n",
      " 22  Amazon Music Playlist Count  377 non-null    float64\n",
      " 23  Pandora Streams              2961 non-null   object \n",
      " 24  Pandora Track Stations       1600 non-null   object \n",
      " 25  Soundcloud Streams           781 non-null    object \n",
      " 26  Shazams                      4975 non-null   object \n",
      " 27  TIDAL Popularity             0 non-null      float64\n",
      " 28  Explicit Track               6800 non-null   int64  \n",
      " 29  Shortlists                   0 non-null      float64\n",
      "dtypes: float64(7), int64(1), object(22)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#Chek for null values and type\n",
    "chart_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc6af4",
   "metadata": {},
   "source": [
    "### We are seeing a lot of null data in the dataset, however we are mostly interested in Spotify stream counts, as it is the biggest platform. We are also seeing that a lot of numeric data is identified as object, which we will correct as well.  So we will reload the dataset only using the relevant columns, correct data types and decide what to do with null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fdf8e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005588235294117672\n"
     ]
    }
   ],
   "source": [
    "null_count=chart_ds['Spotify Streams'].count()\n",
    "null_perc = 1-null_count/chart_ds.shape[0]\n",
    "print(null_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7d8d304",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '808,166,393'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1113\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('O') to dtype('float64') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#we are only missing a tiny proportion of data in spotify streams column. We could safely drop the null values\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#define list of columns to load:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m28\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m chart_ds \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data_path\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchartmetric_raw.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpotify Streams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m chart_ds\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1252\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1026\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1119\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '808,166,393'"
     ]
    }
   ],
   "source": [
    "\n",
    "#we are only missing a tiny proportion of data in spotify streams column. We could safely drop the null values\n",
    "#define list of columns to load:\n",
    "cols = [0,2,3,4,7,28]\n",
    "chart_ds = pd.read_csv(raw_data_path/ \"chartmetric_raw.csv\", usecols=cols, parse_dates = [2], thousands=\",\", keep_default_na=False,\n",
    "                       na_filter=False, dtype = {'Spotify Streams':np.float64})\n",
    "chart_ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "337b0714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6800 entries, 0 to 6799\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Track            6800 non-null   object        \n",
      " 1   Artists          6800 non-null   object        \n",
      " 2   Release Date     6800 non-null   datetime64[ns]\n",
      " 3   ISRC             6800 non-null   object        \n",
      " 4   Spotify Streams  6762 non-null   object        \n",
      " 5   Explicit Track   6800 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 318.9+ KB\n"
     ]
    }
   ],
   "source": [
    "chart_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325e99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739861d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
